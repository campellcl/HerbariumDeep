Runtime configuration for GoingDeeperTransferLearn.py (Going Deeper in the Automated Id. data set):
D:\data\GoingDeeperData -v -a inception_v3 --resume ../../data/PTCheckpoints/model_best.pth.tar

Runtime configuration for GoingDeeperTransferLearn.py (Going Deeper in the Automated Id. data SUB-set):
C:\Users\ccamp\Documents\GitHub\HerbariumDeep\data\GoingDeeper -v -a inception_v3 --resume ../../data/PTCheckpoints/model_best.pth.tar

Runtime configuration for InceptionV3TransferLearn.py:
C:\Users\ccamp\Documents\GitHub\HerbariumDeep\data\ImageNet\SubSets\hymenoptera_data -j 2 -b 6 --pretrained

Runtime configuration for TensorFlow TensorFlow Hub retrain_example.py:
Execute: python C:\Users\ccamp\Documents\GitHub\HerbariumDeep\frameworks\TensorFlow\TFHub\retrain_example.py
--image_dir D:\data\GoingDeeperData\images\train --output_graph ..\Output --intermediate_store_frequency 1 --how_many_training_steps 1 --train_batch_size 64 --test_batch_size 64 --bottleneck_dir ..\Bottlenecks --saved_model_dir ..\\Output\\model_graph.record --tfhub_module https://tfhub.dev/google/imagenet/inception_v3/classification/1 --intermediate_output_dir ..\TBLogs

Debug configuration for TensorFlow TensorFlow Hub retrain_example.py:
--image_dir C:\Users\ccamp\Documents\GitHub\HerbariumDeep\data\GoingDeeper\images --bottleneck_dir ..\SubsetBottlenecks

Runtime configuration for TFHub\GoingDeeperTransferLearn.py:
--image_dir D:\data\GoingDeeperData\images --train_image_dir D:\data\GoingDeeperData\images\train --test_image_dir D:\data\GoingDeeperData\images\test --bottleneck_dir D:\data\GoingDeeperData\Bottlenecks --num_epochs 100000 --intermediate_store_frequency 1000
--image_dir D:\data\GoingDeeperData\images --bottleneck_dir D:\data\GoingDeeperData\Bottlenecks --num_epochs 200000 --intermediate_store_frequency 1000
--image_dir D:\data\GoingDeeperData\images --bottleneck_dir D:\data\GoingDeeperData\Bottlenecks --num_epochs 200000 --intermediate_store_frequency 1000 --train_batch_size 128 --eval_step_interval 1000
# Bottleneck path included for bottleneck restore from dataframe:
--image_dir D:\data\GoingDeeperData\images --bottleneck_dir D:\data\GoingDeeperData\Bottlenecks --bottleneck_path D:\data\GoingDeeperData\bottlenecks.pkl --num_epochs 200000 --intermediate_store_frequency 1000 --train_batch_size 128 --eval_step_interval 1000

Debug configuration for TFHub\GoingDeeperTransferLearn.py:
--image_dir C:\Users\ccamp\Documents\GitHub\HerbariumDeep\data\GoingDeeper\images --train_image_dir C:\Users\ccamp\Documents\GitHub\HerbariumDeep\data\GoingDeeper\images\train --test_image_dir C:\Users\ccamp\Documents\GitHub\HerbariumDeep\data\GoingDeeper\images\test --bottleneck_dir ..\SubsetBottlenecks --num_epochs 100 --intermediate_store_frequency 10
--image_dir C:\Users\ccamp\Documents\GitHub\HerbariumDeep\data\GoingDeeper\images --bottleneck_dir ..\SubsetBottlenecks --num_epochs 100 --intermediate_store_frequency 10
# Bottleneck path included for bottleneck restore from dataframe:
--image_dir C:\Users\ccamp\Documents\GitHub\HerbariumDeep\data\GoingDeeper\images --bottleneck_dir ..\SubsetBottlenecks --bottleneck_path D:\data\GoingDeeperData\bottlenecks.pkl --num_epochs 100 --intermediate_store_frequency 10
# Restore a trained model for evaluation purposes:
--image_dir C:\Users\ccamp\Documents\GitHub\HerbariumDeep\data\GoingDeeper\images --bottleneck_dir ..\SubsetBottlenecks --num_epochs 100 --intermediate_store_frequency 10 --saved_model_path tmp/saved_model.pb
# Resume training by restoring from a checkpoint:

C:\Users\ccamp\Documents\GitHub\HerbariumDeep\data\ImageNet\SubSets\hymenoptera_data -a inception_v3 -j 2 -b 6 --pretrained

Runtime configuration for TFHub\GoingDeeper.py:
--use_case train --training_state new_model --init_type random -train_batch_size -1 --learning_rate_type dynamic --dynamic_learning_rate_type optimization_algorithm --optimizer_type adaptive_optimizer --learning_rate_optimizer tf.train.MomentumOptimizer --momentum 0.9 --image_dir D:\data\GoingDeeperData\images --bottleneck_path D:\data\GoingDeeperData\bottlenecks.pkl --num_epochs 10000 --summaries_dir tmp\summaries

Debug configuration for TFHub\GoingDeeper.py:
# Static learning rate:
--use_case train --training_state new_model --tfhub_module https://tfhub.dev/google/imagenet/inception_v3/feature_vector/1 --init_type random --num_epochs 10000 -learning_rate_type static --learning_rate 0.01 -train_batch_size -1 -val_batch_size -1 --image_dir C:\Users\ccamp\Documents\GitHub\HerbariumDeep\data\GoingDeeper\images --bottleneck_path TFHub\bottlenecks.pkl --summaries_dir tmp\summaries
